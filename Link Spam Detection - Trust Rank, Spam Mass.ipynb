{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcSeJvHw18oa/FNYCM5+Tv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"28tmLs7rXR7Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677309026761,"user_tz":-330,"elapsed":29005,"user":{"displayName":"ARYAN PANDEY 20BLC1087","userId":"13096643247134257430"}},"outputId":"974f3f45-83c4-498f-d3a2-2f3940f06293"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scipy==1.8.0\n","  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scipy==1.8.0) (1.22.4)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","Successfully installed scipy-1.8.0\n"]}],"source":["!pip install 'scipy==1.8.0'"]},{"cell_type":"code","source":["def trust_propagation(graph, trusted_pages):\n","    trust_scores = {page: 0 for page in graph}\n","    for page in trusted_pages:\n","        trust_scores[page] = 1\n","\n","    for _ in range(10):  # number of iterations\n","        new_trust_scores = {page: 0 for page in graph}\n","        for page in graph:\n","            for neighbor in graph[page]:\n","                new_trust_scores[neighbor] += trust_scores[page] / len(graph[page])\n","        trust_scores = new_trust_scores\n","\n","    return trust_scores\n"],"metadata":{"id":"YZfIMF_0XWH3","executionInfo":{"status":"ok","timestamp":1677309028900,"user_tz":-330,"elapsed":3,"user":{"displayName":"ARYAN PANDEY 20BLC1087","userId":"13096643247134257430"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def spam_propagation(graph, spam_pages):\n","    spam_scores = {page: 0 for page in graph}\n","    for page in spam_pages:\n","        spam_scores[page] = 1\n","\n","    for _ in range(10):  # number of iterations\n","        new_spam_scores = {page: 0 for page in graph}\n","        for page in graph:\n","            for neighbor in graph[page]:\n","                new_spam_scores[neighbor] += spam_scores[page] / len(graph[page])\n","        spam_scores = new_spam_scores\n","\n","    return spam_scores\n"],"metadata":{"id":"R46MuGQFXYHH","executionInfo":{"status":"ok","timestamp":1677309036219,"user_tz":-330,"elapsed":2,"user":{"displayName":"ARYAN PANDEY 20BLC1087","userId":"13096643247134257430"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def identify_link_spam(graph, trusted_pages, spam_pages):\n","    trust_scores = trust_propagation(graph, trusted_pages)\n","    spam_scores = spam_propagation(graph, spam_pages)\n","    threshold = 0.5  # adjust this threshold as needed\n","    link_spam = set()\n","    for page in graph:\n","        if spam_scores[page] > threshold and trust_scores[page] < threshold:\n","            link_spam.add(page)\n","    return link_spam\n"],"metadata":{"id":"4tF1layzXeRs","executionInfo":{"status":"ok","timestamp":1677309037822,"user_tz":-330,"elapsed":2,"user":{"displayName":"ARYAN PANDEY 20BLC1087","userId":"13096643247134257430"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def main():\n","    # Collecting the data\n","    graph = {\n","        'page1': ['page2', 'page3', 'page4'],\n","        'page2': ['page1', 'page3', 'page5'],\n","        'page3': ['page1', 'page2', 'page4', 'page5', 'page6'],\n","        'page4': ['page1', 'page3', 'page5', 'page6'],\n","        'page5': ['page2', 'page3', 'page4', 'page6'],\n","        'page6': ['page3', 'page4', 'page5'],\n","        'page7': ['page3', 'page4']\n","    }\n","\n","    # Computing the Trust Rank\n","    trusted_pages = ['page1', 'page2']\n","    trust_scores = trust_propagation(graph, trusted_pages)\n","    print('Trust Scores:')\n","    print(trust_scores)\n","\n","    # Computing the Spam Mass\n","    spam_pages = ['page7']\n","    spam_scores = spam_propagation(graph, spam_pages)\n","    print('Spam Scores:')\n","    print(spam_scores)\n","\n","    # Identifying Link Spam\n","    link_spam = identify_link_spam(graph, trusted_pages, spam_pages)\n","    print('Link Spam:')\n","    print(link_spam)\n","\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"CcN7TfvJXfva","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677309043718,"user_tz":-330,"elapsed":717,"user":{"displayName":"ARYAN PANDEY 20BLC1087","userId":"13096643247134257430"}},"outputId":"ba711dd5-5289-42b8-af0e-a8e7c61c6dc8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Trust Scores:\n","{'page1': 0.2727453780196676, 'page2': 0.2727453780196676, 'page3': 0.4545023604839423, 'page4': 0.3636179594385752, 'page5': 0.3636179594385752, 'page6': 0.2727709645995722, 'page7': 0}\n","Spam Scores:\n","{'page1': 0.13722598769869498, 'page2': 0.13555010211634685, 'page3': 0.22721365975401894, 'page4': 0.1809552887315464, 'page5': 0.18263117431389453, 'page6': 0.1364237873854984, 'page7': 0}\n","Link Spam:\n","set()\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","# Load the SMS text message dataset\n","data = pd.read_csv('sms_spam.csv')\n","\n","# Preprocess the text data\n","vectorizer = CountVectorizer(stop_words='english')\n","X = vectorizer.fit_transform(data['text'])\n","y = data['type'].map({'spam': 1, 'ham': 0})\n","\n","# Split the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train a Naive Bayes classifier on the training set\n","classifier = MultinomialNB()\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set and evaluate the performance of the model\n","y_pred = classifier.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","confusion = confusion_matrix(y_test, y_pred)\n","print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n","print(\"Confusion matrix:\\n\", confusion)\n"],"metadata":{"id":"7hJo52P9XhnM","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1677309055824,"user_tz":-330,"elapsed":1401,"user":{"displayName":"ARYAN PANDEY 20BLC1087","userId":"13096643247134257430"}},"outputId":"a3be4a5a-5aad-4865-ccee-b593a6de0015"},"execution_count":6,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-48ea13da51d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the SMS text message dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sms_spam.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Preprocess the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sms_spam.csv'"]}]},{"cell_type":"code","source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","G = nx.DiGraph()\n","\n","G.add_edges_from([(1, 2), (2, 3), (3, 2), (2, 4), (4, 5), (5, 6),(5,7)])\n","\n","# Visualize the graph (optional)\n","nx.draw(G, with_labels=True)\n","# Display the graph\n","plt.show()\n"],"metadata":{"id":"PCoonr1ZXjat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install 'scipy==1.8.0'"],"metadata":{"id":"kD_NaMhWXlN1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nx.adjacency_matrix(G).todense())"],"metadata":{"id":"jKicksHOXn7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Define the web graph edges\n","edges = [(1, 2), (2, 3), (3, 2), (2, 4), (4, 5), (5, 6), (5, 7)]\n","\n","# Build the adjacency matrix\n","N = max(max(edge) for edge in edges)\n","A = np.zeros((N, N))\n","for edge in edges:\n","    A[edge[0]-1, edge[1]-1] = 1\n","\n","# Build the transition probability matrix\n","P = A / A.sum(axis=1, keepdims=True)\n","\n","# Build the damping vector\n","d = np.ones((N, 1)) / N\n","\n","# Set the initial TrustRank vector for the seed pages\n","s = np.zeros((N, 1))\n","s[[1, 2, 3], 0] = 1/3\n","import numpy as np\n","\n","# Define the web graph edges\n","edges = [(1, 2), (2, 3), (3, 2), (2, 4), (4, 5), (5, 6), (5, 7)]\n","\n","# Build the adjacency matrix\n","N = max(max(edge) for edge in edges)\n","A = np.zeros((N, N))\n","for edge in edges:\n","    A[edge[0]-1, edge[1]-1] = 1\n","\n","# Build the transition probability matrix\n","P = A / A.sum(axis=1, keepdims=True)\n","\n","# Build the damping vector\n","d = np.ones((N, 1)) / N\n","\n","# Set the initial TrustRank vector for the seed pages\n","s = np.zeros((N, 1))\n","s[[1, 2, 3], 0] = 1/3\n","\n","# Set the damping factor\n","alpha = 0.15\n","\n","# Compute the TrustRank iteratively\n","for i in range(20):  # perform 20 iterations\n","    s = (1 - alpha) * P.T @ s + alpha * d\n","\n","# Print the final TrustRank vector\n","print(s)\n","\n","# Set the damping factor\n","alpha = 0.15\n","\n","# Compute the TrustRank iteratively\n","for i in range(20):  # perform 20 iterations\n","    s = (1 - alpha) * P.T @ s + alpha * d\n","\n","# Print the final TrustRank vector\n","print(s)"],"metadata":{"id":"NhLXoFsHXpiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Define the web graph edges\n","A = np.array([[0, 1, 0, 0, 0, 0, 0],\n","              [0, 0, 1, 1, 0, 0, 0],\n","              [0, 1, 0, 0, 0, 0, 0],\n","              [0, 0, 0, 0, 1, 0, 0],\n","              [0, 0, 0, 0, 0, 1, 1],\n","              [0, 0, 0, 0, 0, 0, 0],\n","              [0, 0, 0, 0, 0, 0, 0]])\n","\n","# Build the transition probability matrix\n","P = A / A.sum(axis=1, keepdims=True)\n","\n","# Build the damping vector\n","d = np.ones((7, 1)) / 7\n","\n","# Set the initial TrustRank vector for the seed pages\n","s = np.zeros((7, 1))\n","s[[1, 2, 3], 0] = 1/3\n","\n","# Set the damping factor\n","alpha = 0.15\n","\n","# Compute the TrustRank iteratively\n","for i in range(20):  # perform 20 iterations\n","    s = (1 - alpha) * P.T @ s + alpha * d\n","\n","# Print the final TrustRank vector\n","print(\"TrustRank vector:\")\n","print(s)\n","\n","# Find the TrustRank for pages 2, 3, and 4\n","s_2 = (1 - alpha) * (P.T[1,:] @ s) + alpha / 7\n","s_3 = (1 - alpha) * (P.T[2,:] @ s) + alpha / 7\n","s_4 = (1 - alpha) * (P.T[3,:] @ s) + alpha / 7\n","\n","# Print the TrustRank for pages 2, 3, and 4\n","print(\"TrustRank for page 2:\", s_2)\n","print(\"TrustRank for page 3:\", s_3)\n","print(\"TrustRank for page 4:\", s_4)"],"metadata":{"id":"kGR4_tG5XpdH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def trust_rank(graph, seed, d=0.15, max_iter=100, tol=1e-6):\n","    n = graph.shape[0]\n","    # Initialize the TrustRank vector\n","    s = np.zeros((n, 1))\n","    for i in seed:\n","        s[i] = 1 / len(seed)\n","    # Normalize the graph matrix\n","    a = np.zeros_like(graph, dtype=float)\n","    for i in range(n):\n","        out_degree = np.sum(graph[i])\n","        if out_degree == 0:\n","            a[i] = np.ones(n) / n\n","        else:\n","            a[i] = graph[i] / out_degree\n","    # Compute the TrustRank vector iteratively\n","    for _ in range(max_iter):\n","        s_new = (1 - d) * np.dot(a, s) + d / n\n","        if np.abs(s_new - s).max() < tol:\n","            break\n","        s = s_new\n","    # Compute the TrustRank for the seed pages\n","    trust_rank = {}\n","    for i in seed:\n","        trust_rank[i] = s[i][0]\n","    return s, trust_rank\n","\n","# Define the web graph\n","graph = np.array([[0, 1, 0, 0, 0, 0, 0],\n","                  [0, 0, 1, 1, 0, 0, 0],\n","                  [0, 1, 0, 0, 0, 0, 0],\n","                  [0, 0, 0, 0, 1, 0, 0],\n","                  [0, 0, 0, 0, 0, 1, 1],\n","                  [0, 0, 0, 0, 0, 0, 0],\n","                  [0, 0, 0, 0, 0, 0, 0]])\n","\n","# Compute the TrustRank with seed pages {2, 3, 4} and damping factor 0.15\n","s, trust_rank = trust_rank(graph, seed=[2, 3, 4], d=0.15)\n","\n","# Print the TrustRank vector and the TrustRank for pages 2, 3, and 4\n","print(\"TrustRank vector:\")\n","print(s)\n","print(\"TrustRank for page 2:\", trust_rank[2])\n","print(\"TrustRank for page 3:\", trust_rank[3])\n","print(\"TrustRank for page 4:\", trust_rank[4])"],"metadata":{"id":"IHD8jQvxXtsu"},"execution_count":null,"outputs":[]}]}