{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxpM+6rKlcBt91uk7R+uDf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coJYTCQxc8bm","executionInfo":{"status":"ok","timestamp":1681353229787,"user_tz":-330,"elapsed":5647,"user":{"displayName":"ANANYA B 20BLC1016","userId":"03182103848739493346"}},"outputId":"5604fbda-9583-472b-ea8f-4540d3d10c5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1/1 [==============================] - 3s 3s/step - loss: 0.6537 - accuracy: 0.6667 - val_loss: 0.8305 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","1/1 [==============================] - 0s 87ms/step - loss: 0.6476 - accuracy: 0.6667 - val_loss: 0.8279 - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","1/1 [==============================] - 0s 104ms/step - loss: 0.6415 - accuracy: 0.6667 - val_loss: 0.8252 - val_accuracy: 0.0000e+00\n","Epoch 4/10\n","1/1 [==============================] - 0s 89ms/step - loss: 0.6354 - accuracy: 0.6667 - val_loss: 0.8226 - val_accuracy: 0.0000e+00\n","Epoch 5/10\n","1/1 [==============================] - 0s 45ms/step - loss: 0.6297 - accuracy: 0.6667 - val_loss: 0.8201 - val_accuracy: 0.0000e+00\n","Epoch 6/10\n","1/1 [==============================] - 0s 60ms/step - loss: 0.6241 - accuracy: 0.6667 - val_loss: 0.8176 - val_accuracy: 0.0000e+00\n","Epoch 7/10\n","1/1 [==============================] - 0s 90ms/step - loss: 0.6186 - accuracy: 0.6667 - val_loss: 0.8153 - val_accuracy: 0.0000e+00\n","Epoch 8/10\n","1/1 [==============================] - 0s 96ms/step - loss: 0.6130 - accuracy: 0.6667 - val_loss: 0.8130 - val_accuracy: 0.0000e+00\n","Epoch 9/10\n","1/1 [==============================] - 0s 51ms/step - loss: 0.6075 - accuracy: 0.6667 - val_loss: 0.8107 - val_accuracy: 0.0000e+00\n","Epoch 10/10\n","1/1 [==============================] - 0s 64ms/step - loss: 0.6020 - accuracy: 0.6667 - val_loss: 0.8084 - val_accuracy: 0.0000e+00\n","Test loss: 0.6325863599777222\n","Test accuracy: 1.0\n","1/1 [==============================] - 0s 73ms/step\n","[[0.4195174]\n"," [0.3464254]]\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","data = {'text': ['Hi there, how are you?', 'Get free money now!', 'Thanks for your help today', 'Buy one get one free offer', 'Congratulations, you won a prize!'],\n","        'label': [0, 1, 0, 1, 1]}\n","df = pd.DataFrame(data)\n","\n","tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts(df['text'])\n","\n","X = tokenizer.texts_to_matrix(df['text'])\n","y = np.array(df['label'])\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n","\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print(f'Test loss: {score[0]}')\n","print(f'Test accuracy: {score[1]}')\n","\n","new_text = ['Free offer! Claim your prize now', 'Hello, how are you?']\n","new_text_vec = tokenizer.texts_to_matrix(new_text)\n","predictions = model.predict(new_text_vec)\n","\n","print(predictions)\n"]}]}